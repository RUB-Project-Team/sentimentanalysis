{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install textblob\n",
    "#pip install tweepy\n",
    "#pip install afinn\n",
    "#pip install autocorrect\n",
    "#nltk.download('punkt')\n",
    "#nltk.download('wordnet')\n",
    "#nltk.download('stopwords')\n",
    "#nltk.download('averaged_perceptron_tagger')\n",
    "#nltk.download('sentiwordnet')\n",
    "#pip install spacy vaderSentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencis\n",
    "import pandas as pd\n",
    "import itertools  \n",
    "from textblob import TextBlob\n",
    "import sys, tweepy\n",
    "from requests.exceptions import Timeout, ConnectionError\n",
    "from requests.packages.urllib3.exceptions import ReadTimeoutError\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import ssl\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') # Hides warning\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\",category=UserWarning)\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from techniques import *\n",
    "from autocorrect import Speller\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File paths\n",
    "tweet_data_file = os.path.join(\"..\",\"Resources\",\"inputData\")\n",
    "cleaned_tweet_file=os.path.join(\"..\",\"..\",\"Resources\",\"outputData\",\"tweetCleandata.csv\")\n",
    "extension = 'csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change directory to read files\n",
    "os.chdir(tweet_data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read all csv files\n",
    "all_filenames = [i for i in glob.glob('*.{}'.format(extension))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Data\n",
    "- Social media data is unstructured -it’s raw, noisy, and needs to be cleaned before we can start working on our sentiment analysis model. \n",
    "- Preprocessing a Twitter dataset involves a series of tasks like removing all types of irrelevant information like emojis, special characters, and extra blank spaces. It can also involve making format improvements, delete duplicate tweets, or tweets that are shorter than three characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine all files in the list\n",
    "tweet_df = pd.concat([pd.read_csv(f) for f in all_filenames ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tweetAPISearch_4July.csv',\n",
       " 'tweetAPISearch_5July.csv',\n",
       " 'tweetAPISearch_6July.csv',\n",
       " 'tweetAPISearch_7July.csv',\n",
       " 'tweetAPISearch_8July.csv']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List of files bing processed\n",
    "all_filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 68583 entries, 0 to 9564\n",
      "Data columns (total 10 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   Tweet             56886 non-null  object \n",
      " 1   Matched Keywords  56886 non-null  object \n",
      " 2   Date              56886 non-null  object \n",
      " 3   User              56886 non-null  object \n",
      " 4   Source            56879 non-null  object \n",
      " 5   Tweet ID          56886 non-null  float64\n",
      " 6   Tweet URL         56886 non-null  object \n",
      " 7   Followers         56886 non-null  float64\n",
      " 8   Friends           56886 non-null  float64\n",
      " 9   Favorite          56886 non-null  float64\n",
      "dtypes: float64(4), object(6)\n",
      "memory usage: 5.8+ MB\n"
     ]
    }
   ],
   "source": [
    "# Check df info\n",
    "tweet_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Trump    47262\n",
       "Biden     9624\n",
       "Name: Matched Keywords, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get value count for each keyword\n",
    "tweet_df['Matched Keywords'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets copy column \n",
    "tweet_df['CleanedTweet'] = tweet_df['Tweet'].apply(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Tweet ID from URL\n",
    "tweet_df['TweetID'] = tweet_df['Tweet URL'].apply(str).apply(lambda x: x.split(\"/\")[4] if (len(x)>29) else 0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change data type of TweetID\n",
    "tweet_df['TweetID'] =tweet_df['TweetID'].apply(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets clean the tweet data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Remove unicode\n",
    "tweet_df['CleanedTweet']=tweet_df['CleanedTweet'].apply(lambda x: removeUnicode(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>CleanedTweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Trump: TikTok Must Sell Its American Operation...</td>\n",
       "      <td>Trump: TikTok Must Sell Its American Operation...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@richardmarx I need whatever the reporter is t...</td>\n",
       "      <td>@richardmarx I need whatever the reporter is t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@GOPChairwoman President Trump &amp; the RNC keep ...</td>\n",
       "      <td>@GOPChairwoman President Trump &amp; the RNC keep ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@realDonaldTrump \\n\"Donald Trump dumped $400 m...</td>\n",
       "      <td>@realDonaldTrump \\n\"Donald Trump dumped $400 m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This is how every single journalist should be ...</td>\n",
       "      <td>This is how every single journalist should be ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9560</th>\n",
       "      <td>@JoeBiden We know Joe Biden love The Chinese C...</td>\n",
       "      <td>@JoeBiden We know Joe Biden love The Chinese C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9561</th>\n",
       "      <td>@KayaJones I like Trump but this was already i...</td>\n",
       "      <td>@KayaJones I like Trump but this was already i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9562</th>\n",
       "      <td>@JoeBiden Is there a person of sound mind in t...</td>\n",
       "      <td>@JoeBiden Is there a person of sound mind in t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9563</th>\n",
       "      <td>Opinion | We are only beginning to suffer the ...</td>\n",
       "      <td>Opinion | We are only beginning to suffer the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9564</th>\n",
       "      <td>@MeidasTouch Hahaha you guys are f***ing scare...</td>\n",
       "      <td>@MeidasTouch Hahaha you guys are f***ing scare...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>68583 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Tweet  \\\n",
       "0     Trump: TikTok Must Sell Its American Operation...   \n",
       "1     @richardmarx I need whatever the reporter is t...   \n",
       "2     @GOPChairwoman President Trump & the RNC keep ...   \n",
       "3     @realDonaldTrump \\n\"Donald Trump dumped $400 m...   \n",
       "4     This is how every single journalist should be ...   \n",
       "...                                                 ...   \n",
       "9560  @JoeBiden We know Joe Biden love The Chinese C...   \n",
       "9561  @KayaJones I like Trump but this was already i...   \n",
       "9562  @JoeBiden Is there a person of sound mind in t...   \n",
       "9563  Opinion | We are only beginning to suffer the ...   \n",
       "9564  @MeidasTouch Hahaha you guys are f***ing scare...   \n",
       "\n",
       "                                           CleanedTweet  \n",
       "0     Trump: TikTok Must Sell Its American Operation...  \n",
       "1     @richardmarx I need whatever the reporter is t...  \n",
       "2     @GOPChairwoman President Trump & the RNC keep ...  \n",
       "3     @realDonaldTrump \\n\"Donald Trump dumped $400 m...  \n",
       "4     This is how every single journalist should be ...  \n",
       "...                                                 ...  \n",
       "9560  @JoeBiden We know Joe Biden love The Chinese C...  \n",
       "9561  @KayaJones I like Trump but this was already i...  \n",
       "9562  @JoeBiden Is there a person of sound mind in t...  \n",
       "9563  Opinion | We are only beginning to suffer the ...  \n",
       "9564  @MeidasTouch Hahaha you guys are f***ing scare...  \n",
       "\n",
       "[68583 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_df[['Tweet','CleanedTweet']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. Replace URL, hashTag etc.\n",
    "tweet_df['CleanedTweet']=tweet_df['CleanedTweet'].apply(lambda x: replaceURL(x))\n",
    "tweet_df['CleanedTweet']=tweet_df['CleanedTweet'].apply(lambda x: replaceAtUser(x))\n",
    "tweet_df['CleanedTweet']=tweet_df['CleanedTweet'].apply(lambda x: removeHashtagInFrontOfWord(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. Replace slang words and abbreviations with their equivalents\n",
    "tweet_df['CleanedTweet']=tweet_df['CleanedTweet'].apply(lambda x: replaceSlang(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4. Replace contractions to their equivalents\n",
    "tweet_df['CleanedTweet']=tweet_df['CleanedTweet'].apply(lambda x: replaceContraction(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5. Remove integers from text\n",
    "tweet_df['CleanedTweet']=tweet_df['CleanedTweet'].apply(lambda x: removeNumbers(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#6. Remove emoticons from text   \n",
    "tweet_df['CleanedTweet']=tweet_df['CleanedTweet'].apply(lambda x: removeEmoticons(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#7. Replace repetitions of exlamation marks,question marks and stop marks\n",
    "tweet_df['CleanedTweet']=tweet_df['CleanedTweet'].apply(lambda x: replaceMultiExclamationMark(x))\n",
    "tweet_df['CleanedTweet']=tweet_df['CleanedTweet'].apply(lambda x: replaceMultiQuestionMark(x))\n",
    "tweet_df['CleanedTweet']=tweet_df['CleanedTweet'].apply(lambda x: replaceMultiStopMark(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>CleanedTweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Trump: TikTok Must Sell Its American Operation...</td>\n",
       "      <td>Trump TikTok Must Sell Its American Operations...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@richardmarx I need whatever the reporter is t...</td>\n",
       "      <td>atUser I need whatever the reporter is taking ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@GOPChairwoman President Trump &amp; the RNC keep ...</td>\n",
       "      <td>atUser President Trump and the RNC keep sendin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@realDonaldTrump \\n\"Donald Trump dumped $400 m...</td>\n",
       "      <td>atUser \\n\"Donald Trump dumped $ million into h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This is how every single journalist should be ...</td>\n",
       "      <td>This is how every single journalist should be ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9560</th>\n",
       "      <td>@JoeBiden We know Joe Biden love The Chinese C...</td>\n",
       "      <td>atUser We know Joe Biden love The Chinese Comm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9561</th>\n",
       "      <td>@KayaJones I like Trump but this was already i...</td>\n",
       "      <td>atUser I like Trump but this was already in Ob...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9562</th>\n",
       "      <td>@JoeBiden Is there a person of sound mind in t...</td>\n",
       "      <td>atUser Is there a person of sound mind in the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9563</th>\n",
       "      <td>Opinion | We are only beginning to suffer the ...</td>\n",
       "      <td>Opinion | We are only beginning to suffer the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9564</th>\n",
       "      <td>@MeidasTouch Hahaha you guys are f***ing scare...</td>\n",
       "      <td>atUser Hahaha you guys are f***ing scared   fo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>68583 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Tweet  \\\n",
       "0     Trump: TikTok Must Sell Its American Operation...   \n",
       "1     @richardmarx I need whatever the reporter is t...   \n",
       "2     @GOPChairwoman President Trump & the RNC keep ...   \n",
       "3     @realDonaldTrump \\n\"Donald Trump dumped $400 m...   \n",
       "4     This is how every single journalist should be ...   \n",
       "...                                                 ...   \n",
       "9560  @JoeBiden We know Joe Biden love The Chinese C...   \n",
       "9561  @KayaJones I like Trump but this was already i...   \n",
       "9562  @JoeBiden Is there a person of sound mind in t...   \n",
       "9563  Opinion | We are only beginning to suffer the ...   \n",
       "9564  @MeidasTouch Hahaha you guys are f***ing scare...   \n",
       "\n",
       "                                           CleanedTweet  \n",
       "0     Trump TikTok Must Sell Its American Operations...  \n",
       "1     atUser I need whatever the reporter is taking ...  \n",
       "2     atUser President Trump and the RNC keep sendin...  \n",
       "3     atUser \\n\"Donald Trump dumped $ million into h...  \n",
       "4     This is how every single journalist should be ...  \n",
       "...                                                 ...  \n",
       "9560  atUser We know Joe Biden love The Chinese Comm...  \n",
       "9561  atUser I like Trump but this was already in Ob...  \n",
       "9562  atUser Is there a person of sound mind in the ...  \n",
       "9563  Opinion | We are only beginning to suffer the ...  \n",
       "9564  atUser Hahaha you guys are f***ing scared   fo...  \n",
       "\n",
       "[68583 rows x 2 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_df[['Tweet','CleanedTweet']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmPunctuation(text):\n",
    "    return re.sub(r'[^\\w\\s]', '', text) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8: Remove punctuation\n",
    "tweet_df['CleanedTweet']=tweet_df['CleanedTweet'].apply(lambda x: rmPunctuation(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predTweet Column to have a minnigful sentence for predictor\n",
    "tweet_df['predTweet']=tweet_df['CleanedTweet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predTweet</th>\n",
       "      <th>CleanedTweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Trump TikTok Must Sell Its American Operations...</td>\n",
       "      <td>Trump TikTok Must Sell Its American Operations...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>atUser I need whatever the reporter is taking ...</td>\n",
       "      <td>atUser I need whatever the reporter is taking ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>atUser President Trump and the RNC keep sendin...</td>\n",
       "      <td>atUser President Trump and the RNC keep sendin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>atUser \\nDonald Trump dumped  million into his...</td>\n",
       "      <td>atUser \\nDonald Trump dumped  million into his...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This is how every single journalist should be ...</td>\n",
       "      <td>This is how every single journalist should be ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9560</th>\n",
       "      <td>atUser We know Joe Biden love The Chinese Comm...</td>\n",
       "      <td>atUser We know Joe Biden love The Chinese Comm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9561</th>\n",
       "      <td>atUser I like Trump but this was already in Ob...</td>\n",
       "      <td>atUser I like Trump but this was already in Ob...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9562</th>\n",
       "      <td>atUser Is there a person of sound mind in the ...</td>\n",
       "      <td>atUser Is there a person of sound mind in the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9563</th>\n",
       "      <td>Opinion  We are only beginning to suffer the c...</td>\n",
       "      <td>Opinion  We are only beginning to suffer the c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9564</th>\n",
       "      <td>atUser Hahaha you guys are fing scared   for N...</td>\n",
       "      <td>atUser Hahaha you guys are fing scared   for N...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>68583 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              predTweet  \\\n",
       "0     Trump TikTok Must Sell Its American Operations...   \n",
       "1     atUser I need whatever the reporter is taking ...   \n",
       "2     atUser President Trump and the RNC keep sendin...   \n",
       "3     atUser \\nDonald Trump dumped  million into his...   \n",
       "4     This is how every single journalist should be ...   \n",
       "...                                                 ...   \n",
       "9560  atUser We know Joe Biden love The Chinese Comm...   \n",
       "9561  atUser I like Trump but this was already in Ob...   \n",
       "9562  atUser Is there a person of sound mind in the ...   \n",
       "9563  Opinion  We are only beginning to suffer the c...   \n",
       "9564  atUser Hahaha you guys are fing scared   for N...   \n",
       "\n",
       "                                           CleanedTweet  \n",
       "0     Trump TikTok Must Sell Its American Operations...  \n",
       "1     atUser I need whatever the reporter is taking ...  \n",
       "2     atUser President Trump and the RNC keep sendin...  \n",
       "3     atUser \\nDonald Trump dumped  million into his...  \n",
       "4     This is how every single journalist should be ...  \n",
       "...                                                 ...  \n",
       "9560  atUser We know Joe Biden love The Chinese Comm...  \n",
       "9561  atUser I like Trump but this was already in Ob...  \n",
       "9562  atUser Is there a person of sound mind in the ...  \n",
       "9563  Opinion  We are only beginning to suffer the c...  \n",
       "9564  atUser Hahaha you guys are fing scared   for N...  \n",
       "\n",
       "[68583 rows x 2 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display results from earlier steps\n",
    "tweet_df[['predTweet','CleanedTweet']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is just to remove converted charactersets from a tweet that that will be used for prediction\n",
    "def filterStopWords(text):\n",
    "    filterwords = \"multiexclamation multiquestion multistop url atuser am pm\" \n",
    "    finalTokens = [] # all tokens\n",
    "    tokens = text.split()\n",
    "    for w in tokens:\n",
    "        #print(w)\n",
    "        w=w.lower()\n",
    "        # 9. Remove some stopwords\n",
    "        if (w not in filterwords):\n",
    "            #print(w)\n",
    "            final_word = w.lower()\n",
    "            finalTokens.append(final_word)\n",
    "    return \" \".join(finalTokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter stop words\n",
    "tweet_df['predTweet']=tweet_df['predTweet'].apply(lambda x: filterStopWords(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predTweet</th>\n",
       "      <th>CleanedTweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>trump tiktok must sell its american operations...</td>\n",
       "      <td>Trump TikTok Must Sell Its American Operations...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>need whatever the reporter taking keep his coo...</td>\n",
       "      <td>atUser I need whatever the reporter is taking ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>president trump and the rnc keep sending mail ...</td>\n",
       "      <td>atUser President Trump and the RNC keep sendin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>donald trump dumped million into his clubs in ...</td>\n",
       "      <td>atUser \\nDonald Trump dumped  million into his...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>this how every single journalist should be tal...</td>\n",
       "      <td>This is how every single journalist should be ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9560</th>\n",
       "      <td>we know joe biden love the chinese communities...</td>\n",
       "      <td>atUser We know Joe Biden love The Chinese Comm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9561</th>\n",
       "      <td>like trump but this was already in obama care</td>\n",
       "      <td>atUser I like Trump but this was already in Ob...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9562</th>\n",
       "      <td>there person of sound mind in the usa democrat...</td>\n",
       "      <td>atUser Is there a person of sound mind in the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9563</th>\n",
       "      <td>opinion we are only beginning suffer the conse...</td>\n",
       "      <td>Opinion  We are only beginning to suffer the c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9564</th>\n",
       "      <td>hahaha you guys are fing scared for november a...</td>\n",
       "      <td>atUser Hahaha you guys are fing scared   for N...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>68583 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              predTweet  \\\n",
       "0     trump tiktok must sell its american operations...   \n",
       "1     need whatever the reporter taking keep his coo...   \n",
       "2     president trump and the rnc keep sending mail ...   \n",
       "3     donald trump dumped million into his clubs in ...   \n",
       "4     this how every single journalist should be tal...   \n",
       "...                                                 ...   \n",
       "9560  we know joe biden love the chinese communities...   \n",
       "9561      like trump but this was already in obama care   \n",
       "9562  there person of sound mind in the usa democrat...   \n",
       "9563  opinion we are only beginning suffer the conse...   \n",
       "9564  hahaha you guys are fing scared for november a...   \n",
       "\n",
       "                                           CleanedTweet  \n",
       "0     Trump TikTok Must Sell Its American Operations...  \n",
       "1     atUser I need whatever the reporter is taking ...  \n",
       "2     atUser President Trump and the RNC keep sendin...  \n",
       "3     atUser \\nDonald Trump dumped  million into his...  \n",
       "4     This is how every single journalist should be ...  \n",
       "...                                                 ...  \n",
       "9560  atUser We know Joe Biden love The Chinese Comm...  \n",
       "9561  atUser I like Trump but this was already in Ob...  \n",
       "9562  atUser Is there a person of sound mind in the ...  \n",
       "9563  Opinion  We are only beginning to suffer the c...  \n",
       "9564  atUser Hahaha you guys are fing scared   for N...  \n",
       "\n",
       "[68583 rows x 2 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display results from earlier steps\n",
    "tweet_df[['predTweet','CleanedTweet']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizes a text to its words, removes and replaces some of them \n",
    "stoplist = stopwords.words('english')\n",
    "my_stopwords = \"multiexclamation multiquestion multistop gave url atuser st rd nd th am pm\" # my extra stopwords\n",
    "stoplist = stoplist + my_stopwords.split()\n",
    "allowedWordTypes = [\"J\",\"R\",\"V\",\"N\"] #  J is Adject, R is Adverb, V is Verb, N is Noun. These are used for POS Tagging\n",
    "lemmatizer = WordNetLemmatizer() # set lemmatizer\n",
    "stemmer = PorterStemmer() # set stemmer\n",
    "spell = Speller(fast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to lower case words and remove stop words\n",
    "def exCleanup(text):\n",
    "    finalTokens = [] # all tokens\n",
    "    # Get tokens\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    \n",
    "    # 8. Finds \"not\" and antonym for the next word and if found, replaces not and the next word with the antonym\n",
    "    #tokens = replaceNegations(text) \n",
    "        \n",
    "    for w in tokens:\n",
    "        w= w.lower()\n",
    "        # 9. Remove stopwords\n",
    "        if (w not in stoplist):\n",
    "            # 10. lowercases all characters\n",
    "            final_word = w.lower()\n",
    "            finalTokens.append(final_word)\n",
    "\n",
    "  \n",
    "    return finalTokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for text processing - spell check, elongated words, lamatizr and stemming of data\n",
    "def exSpeechTag(text):    \n",
    "    finalTokens = [] # all tokens\n",
    "    tokens = text #as data is alrady tokenized\n",
    "    \n",
    "    for w in tokens:\n",
    "\n",
    "        if (w not in stoplist and len(w)>4):\n",
    "            \n",
    "            # 11. Finds a word with at least 3 characters capitalized and adds the tag ALL_CAPS_\n",
    "            final_word = addCapTag(w)\n",
    "           \n",
    "            # 12. Replaces an elongated word with its basic form, unless the word exists in the lexicon\n",
    "            final_word = replaceElongated(final_word)\n",
    "          \n",
    "            if len(final_word)>1:\n",
    "                # 13. Correction of spelling errors\n",
    "                final_word = spell(final_word)\n",
    "                #print(final_word)\n",
    "            # 14. lemmatizes words   \n",
    "            final_word = lemmatizer.lemmatize(final_word)\n",
    "            # 15. Apply stemming to words\n",
    "            final_word = stemmer.stem(final_word)\n",
    "                          \n",
    "            finalTokens.append(final_word)\n",
    "    return finalTokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize tweet\n",
    "tweet_df['CleanedTweet']=tweet_df['CleanedTweet'].apply(lambda x: exCleanup(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spell check,replace elongated, lammatize and stemming\n",
    "tweet_df['CleanedTweet']=tweet_df['CleanedTweet'].apply(lambda x: exSpeechTag(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>CleanedTweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Trump: TikTok Must Sell Its American Operation...</td>\n",
       "      <td>[trump, tiktok, american, oper]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@richardmarx I need whatever the reporter is t...</td>\n",
       "      <td>[whatev, report, take, exercis, patienc, trump...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@GOPChairwoman President Trump &amp; the RNC keep ...</td>\n",
       "      <td>[presid, trump, send, deceas, husband, tri]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@realDonaldTrump \\n\"Donald Trump dumped $400 m...</td>\n",
       "      <td>[donald, trump, dump, million, club, aberdeen,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This is how every single journalist should be ...</td>\n",
       "      <td>[everi, singl, journalist, talk, everi, trump,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9560</th>\n",
       "      <td>@JoeBiden We know Joe Biden love The Chinese C...</td>\n",
       "      <td>[bien, chines, commun, parti]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9561</th>\n",
       "      <td>@KayaJones I like Trump but this was already i...</td>\n",
       "      <td>[trump, alreadi, obama]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9562</th>\n",
       "      <td>@JoeBiden Is there a person of sound mind in t...</td>\n",
       "      <td>[person, sound, democrat, republican, think, b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9563</th>\n",
       "      <td>Opinion | We are only beginning to suffer the ...</td>\n",
       "      <td>[opinion, begin, suffer, consequ, trump, failu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9564</th>\n",
       "      <td>@MeidasTouch Hahaha you guys are f***ing scare...</td>\n",
       "      <td>[hahaha, scare, novemb, rightli, bien, intervi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>68583 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Tweet  \\\n",
       "0     Trump: TikTok Must Sell Its American Operation...   \n",
       "1     @richardmarx I need whatever the reporter is t...   \n",
       "2     @GOPChairwoman President Trump & the RNC keep ...   \n",
       "3     @realDonaldTrump \\n\"Donald Trump dumped $400 m...   \n",
       "4     This is how every single journalist should be ...   \n",
       "...                                                 ...   \n",
       "9560  @JoeBiden We know Joe Biden love The Chinese C...   \n",
       "9561  @KayaJones I like Trump but this was already i...   \n",
       "9562  @JoeBiden Is there a person of sound mind in t...   \n",
       "9563  Opinion | We are only beginning to suffer the ...   \n",
       "9564  @MeidasTouch Hahaha you guys are f***ing scare...   \n",
       "\n",
       "                                           CleanedTweet  \n",
       "0                       [trump, tiktok, american, oper]  \n",
       "1     [whatev, report, take, exercis, patienc, trump...  \n",
       "2           [presid, trump, send, deceas, husband, tri]  \n",
       "3     [donald, trump, dump, million, club, aberdeen,...  \n",
       "4     [everi, singl, journalist, talk, everi, trump,...  \n",
       "...                                                 ...  \n",
       "9560                      [bien, chines, commun, parti]  \n",
       "9561                            [trump, alreadi, obama]  \n",
       "9562  [person, sound, democrat, republican, think, b...  \n",
       "9563  [opinion, begin, suffer, consequ, trump, failu...  \n",
       "9564  [hahaha, scare, novemb, rightli, bien, intervi...  \n",
       "\n",
       "[68583 rows x 2 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display results from earlier steps\n",
    "tweet_df[['Tweet','CleanedTweet']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change date column format and export only required columns for further processing\n",
    "tweet_df['Date'] = pd.to_datetime(tweet_df['Date'])\n",
    "tweet_df['Date'] = tweet_df['Date'].dt.strftime('%m/%d/%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's clean orginal tweet for spell check \n",
    "tweet_df['Tweet']=tweet_df['Tweet'].apply(str).apply(lambda x: spell(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's clean pred tweet for spell check, removing \n",
    "tweet_df['predTweet']=tweet_df['predTweet'].apply(str).apply(lambda x: spell(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's clean Cleaned Tweet for spell check, removing \n",
    "tweet_df['CleanedTweet']=tweet_df['CleanedTweet'].apply(str).apply(lambda x: spell(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only required columns\n",
    "tweet_df=tweet_df[['TweetID','Date','Matched Keywords','User','Source','Followers','Friends','Favorite','Tweet','predTweet','CleanedTweet']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TweetID</th>\n",
       "      <th>Date</th>\n",
       "      <th>Matched Keywords</th>\n",
       "      <th>User</th>\n",
       "      <th>Source</th>\n",
       "      <th>Followers</th>\n",
       "      <th>Friends</th>\n",
       "      <th>Favorite</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>predTweet</th>\n",
       "      <th>CleanedTweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1290598653770575872</td>\n",
       "      <td>08/04/2020</td>\n",
       "      <td>Trump</td>\n",
       "      <td>genadamedia</td>\n",
       "      <td>GenadaMedia</td>\n",
       "      <td>1685.0</td>\n",
       "      <td>1642.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Trump: TikTok Must Sell Its American Operation...</td>\n",
       "      <td>trump tiktok must sell its american operations...</td>\n",
       "      <td>['trump', 'tiktok', 'american', 'over']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1290598652847816706</td>\n",
       "      <td>08/04/2020</td>\n",
       "      <td>Trump</td>\n",
       "      <td>Carolin64234118</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>@richardmarx I need whatever the reporter is t...</td>\n",
       "      <td>need whatever the reporter taking keep his coo...</td>\n",
       "      <td>['whaten', 'report', 'take', 'exercise', 'pati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1290598651966951424</td>\n",
       "      <td>08/04/2020</td>\n",
       "      <td>Trump</td>\n",
       "      <td>soulb4time</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>42.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>@GOPChairwoman President Trump &amp; the RN keep s...</td>\n",
       "      <td>president trump and the rec keep sending mail ...</td>\n",
       "      <td>['preside', 'trump', 'send', 'decease', 'husba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1290598649626599424</td>\n",
       "      <td>08/04/2020</td>\n",
       "      <td>Trump</td>\n",
       "      <td>Jan714</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>39.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>@realDonaldTrump \\n\"Donald Trump dumped $400 m...</td>\n",
       "      <td>donald trump dumped million into his clubs in ...</td>\n",
       "      <td>['donald', 'trump', 'dump', 'million', 'club',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1290598646740848640</td>\n",
       "      <td>08/04/2020</td>\n",
       "      <td>Trump</td>\n",
       "      <td>jocfanaccount</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>659.0</td>\n",
       "      <td>730.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>This is how every single journalist should be ...</td>\n",
       "      <td>this how every single journalist should be tal...</td>\n",
       "      <td>['every', 'single', 'journalist', 'talk', 'eve...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               TweetID        Date Matched Keywords             User  \\\n",
       "0  1290598653770575872  08/04/2020            Trump      genadamedia   \n",
       "1  1290598652847816706  08/04/2020            Trump  Carolin64234118   \n",
       "2  1290598651966951424  08/04/2020            Trump       soulb4time   \n",
       "3  1290598649626599424  08/04/2020            Trump           Jan714   \n",
       "4  1290598646740848640  08/04/2020            Trump    jocfanaccount   \n",
       "\n",
       "                Source  Followers  Friends  Favorite  \\\n",
       "0          GenadaMedia     1685.0   1642.0       0.0   \n",
       "1  Twitter for Android        0.0     41.0       0.0   \n",
       "2      Twitter Web App       42.0    117.0       0.0   \n",
       "3      Twitter Web App       39.0    120.0       0.0   \n",
       "4   Twitter for iPhone      659.0    730.0       0.0   \n",
       "\n",
       "                                               Tweet  \\\n",
       "0  Trump: TikTok Must Sell Its American Operation...   \n",
       "1  @richardmarx I need whatever the reporter is t...   \n",
       "2  @GOPChairwoman President Trump & the RN keep s...   \n",
       "3  @realDonaldTrump \\n\"Donald Trump dumped $400 m...   \n",
       "4  This is how every single journalist should be ...   \n",
       "\n",
       "                                           predTweet  \\\n",
       "0  trump tiktok must sell its american operations...   \n",
       "1  need whatever the reporter taking keep his coo...   \n",
       "2  president trump and the rec keep sending mail ...   \n",
       "3  donald trump dumped million into his clubs in ...   \n",
       "4  this how every single journalist should be tal...   \n",
       "\n",
       "                                        CleanedTweet  \n",
       "0            ['trump', 'tiktok', 'american', 'over']  \n",
       "1  ['whaten', 'report', 'take', 'exercise', 'pati...  \n",
       "2  ['preside', 'trump', 'send', 'decease', 'husba...  \n",
       "3  ['donald', 'trump', 'dump', 'million', 'club',...  \n",
       "4  ['every', 'single', 'journalist', 'talk', 'eve...  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display results\n",
    "tweet_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Clean tweet data for charting and modelling\n",
    "tweet_df.to_csv(cleaned_tweet_file,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
