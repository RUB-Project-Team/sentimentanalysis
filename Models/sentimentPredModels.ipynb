{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tweeter Sentiment Prediction Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install spacy==2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib\n",
    "\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.feature_selection import VarianceThreshold,SelectFromModel,RFECV\n",
    "from sklearn.decomposition import LatentDirichletAllocation,TruncatedSVD\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import MinMaxScaler,LabelEncoder\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier,ExtraTreesRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import train_test_split,cross_val_score,StratifiedKFold\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from model import tokenize\n",
    "\n",
    "import spacy\n",
    "import en_core_web_sm\n",
    "import sys\n",
    "import unicodedata\n",
    "import os\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') # Hides warning\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\",category=UserWarning)\n",
    "np.random.seed(7) # seeding random number generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File paths\n",
    "pred_data_file = os.path.join(\"..\",\"Resources\",\"outputData\",\"tweetCleanData.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Tweeter data file\n",
    "df = pd.read_csv(pred_data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>TweetID</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Matched Keywords</th>\n",
       "      <th>User</th>\n",
       "      <th>Source</th>\n",
       "      <th>Followers</th>\n",
       "      <th>Friends</th>\n",
       "      <th>Favorite</th>\n",
       "      <th>OrgTweet</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8/10/2020</td>\n",
       "      <td>1292795662485130000</td>\n",
       "      <td>even right certain kind liberal deeply wants g...</td>\n",
       "      <td>Trump</td>\n",
       "      <td>MenshevikM</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>5882.0</td>\n",
       "      <td>320.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>They're even right that there's a certain kind...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8/10/2020</td>\n",
       "      <td>1292795661809850000</td>\n",
       "      <td>press people encouraged voters vote trump like...</td>\n",
       "      <td>Trump</td>\n",
       "      <td>balling_it</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>33.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>@jonathanchait Naw, that is the press, people ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8/10/2020</td>\n",
       "      <td>1292795659704240000</td>\n",
       "      <td>trump signs executive order throw rotted scrap...</td>\n",
       "      <td>Trump</td>\n",
       "      <td>laurie71</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>85.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>@sarahcpr Trump signs an executive order to th...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8/10/2020</td>\n",
       "      <td>1292795658747940000</td>\n",
       "      <td>sorry want real team truthful team justice tea...</td>\n",
       "      <td>Biden</td>\n",
       "      <td>bluewave4peace</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>528.0</td>\n",
       "      <td>745.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>@glennkirschner2 Sorry I want to be on a real ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8/10/2020</td>\n",
       "      <td>1292795658550810000</td>\n",
       "      <td>yeah sase cowers yelps befor jumping embarrass...</td>\n",
       "      <td>Trump</td>\n",
       "      <td>OGOPer</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>2839.0</td>\n",
       "      <td>2655.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Yeah. Until Ben Sasse cowers and yelps befor j...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date              TweetID  \\\n",
       "0  8/10/2020  1292795662485130000   \n",
       "1  8/10/2020  1292795661809850000   \n",
       "2  8/10/2020  1292795659704240000   \n",
       "3  8/10/2020  1292795658747940000   \n",
       "4  8/10/2020  1292795658550810000   \n",
       "\n",
       "                                               Tweet Matched Keywords  \\\n",
       "0  even right certain kind liberal deeply wants g...            Trump   \n",
       "1  press people encouraged voters vote trump like...            Trump   \n",
       "2  trump signs executive order throw rotted scrap...            Trump   \n",
       "3  sorry want real team truthful team justice tea...            Biden   \n",
       "4  yeah sase cowers yelps befor jumping embarrass...            Trump   \n",
       "\n",
       "             User              Source  Followers  Friends  Favorite  \\\n",
       "0      MenshevikM     Twitter Web App     5882.0    320.0       0.0   \n",
       "1      balling_it     Twitter Web App       33.0    156.0       0.0   \n",
       "2        laurie71  Twitter for iPhone       85.0    141.0       0.0   \n",
       "3  bluewave4peace  Twitter for iPhone      528.0    745.0       0.0   \n",
       "4          OGOPer  Twitter for iPhone     2839.0   2655.0       0.0   \n",
       "\n",
       "                                            OrgTweet Sentiment  \n",
       "0  They're even right that there's a certain kind...  Positive  \n",
       "1  @jonathanchait Naw, that is the press, people ...  Positive  \n",
       "2  @sarahcpr Trump signs an executive order to th...  Negative  \n",
       "3  @glennkirschner2 Sorry I want to be on a real ...  Positive  \n",
       "4  Yeah. Until Ben Sasse cowers and yelps befor j...  Negative  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display sample results\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TweetID</th>\n",
       "      <th>Followers</th>\n",
       "      <th>Friends</th>\n",
       "      <th>Favorite</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.101460e+05</td>\n",
       "      <td>1.101000e+05</td>\n",
       "      <td>1.101000e+05</td>\n",
       "      <td>110100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.291930e+18</td>\n",
       "      <td>2.747815e+04</td>\n",
       "      <td>2.887499e+03</td>\n",
       "      <td>6.911308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.643205e+16</td>\n",
       "      <td>5.766217e+05</td>\n",
       "      <td>1.194821e+04</td>\n",
       "      <td>138.154460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.291310e+18</td>\n",
       "      <td>7.000000e+01</td>\n",
       "      <td>1.750000e+02</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.292466e+18</td>\n",
       "      <td>3.880000e+02</td>\n",
       "      <td>6.110000e+02</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.293694e+18</td>\n",
       "      <td>2.021000e+03</td>\n",
       "      <td>2.051000e+03</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.294221e+18</td>\n",
       "      <td>5.840372e+07</td>\n",
       "      <td>1.166020e+06</td>\n",
       "      <td>16532.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            TweetID     Followers       Friends       Favorite\n",
       "count  1.101460e+05  1.101000e+05  1.101000e+05  110100.000000\n",
       "mean   1.291930e+18  2.747815e+04  2.887499e+03       6.911308\n",
       "std    2.643205e+16  5.766217e+05  1.194821e+04     138.154460\n",
       "min    0.000000e+00  0.000000e+00  0.000000e+00       0.000000\n",
       "25%    1.291310e+18  7.000000e+01  1.750000e+02       0.000000\n",
       "50%    1.292466e+18  3.880000e+02  6.110000e+02       0.000000\n",
       "75%    1.293694e+18  2.021000e+03  2.051000e+03       1.000000\n",
       "max    1.294221e+18  5.840372e+07  1.166020e+06   16532.000000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Describe data set\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only required columns\n",
    "df_pred = df[['OrgTweet','Tweet','Sentiment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OrgTweet</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>110100</td>\n",
       "      <td>110097</td>\n",
       "      <td>110146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>107431</td>\n",
       "      <td>96701</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>@varindersingh24 Trump</td>\n",
       "      <td>trump</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>26</td>\n",
       "      <td>931</td>\n",
       "      <td>43988</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      OrgTweet   Tweet Sentiment\n",
       "count                   110100  110097    110146\n",
       "unique                  107431   96701         3\n",
       "top     @varindersingh24 Trump   trump  Negative\n",
       "freq                        26     931     43988"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check df stats\n",
    "df_pred.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(110146, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check data dimension - this step is required to make sure we have enough data points to train and test model\n",
    "df_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select meaningful reviews by filtering reviews with more than 5 words in the review comment.\n",
    "df_pred = df_pred[df_pred['Tweet'].fillna(\"\").apply(lambda x: len(x.split())>=5)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(94051, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the data dimension\n",
    "df_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatization and Stop words\n",
    "nlp = en_core_web_sm.load()\n",
    "\n",
    "# Define default stopwords list\n",
    "stoplist = spacy.lang.en.STOP_WORDS \n",
    "\n",
    "# Functions to remove encodes\n",
    "def replace_ptbr_char_by_word(word):\n",
    "    #  \"\"\" Will remove the encode token by token\"\"\"\n",
    "    word = str(word)\n",
    "    word = unicodedata.normalize('NFKD', word).encode('ASCII','ignore').decode('ASCII')\n",
    "    return word\n",
    "\n",
    "def remove_pt_br_char_by_text(text):\n",
    "    #  \"\"\" Will remove the encode using the entire text\"\"\"\n",
    "    text = str(text)\n",
    "    text = \" \".join(replace_ptbr_char_by_word(word) for word in text.split() if word not in stoplist)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatization and Stop words\n",
    "df_pred['predTweet'] = df_pred['Tweet'].apply(remove_pt_br_char_by_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only required columns\n",
    "df_pred=df_pred[['predTweet','Sentiment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 94051 entries, 0 to 110145\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   predTweet  94051 non-null  object\n",
      " 1   Sentiment  94051 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 2.2+ MB\n"
     ]
    }
   ],
   "source": [
    "# Check data types\n",
    "df_pred.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert review_body to text\n",
    "df_pred['predTweet'] = df_pred['predTweet'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predTweet</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>right certain kind liberal deeply wants group ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>press people encouraged voters vote trump like...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>trump signs executive order throw rotted scrap...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sorry want real team truthful team justice tea...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>yeah sase cowers yelps befor jumping embarrass...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           predTweet Sentiment\n",
       "0  right certain kind liberal deeply wants group ...  Positive\n",
       "1  press people encouraged voters vote trump like...  Positive\n",
       "2  trump signs executive order throw rotted scrap...  Negative\n",
       "3  sorry want real team truthful team justice tea...  Positive\n",
       "4  yeah sase cowers yelps befor jumping embarrass...  Negative"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display df sample\n",
    "df_pred.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Term Frequencies\n",
    "- Calculate both the actual term frequency as well as the tfidf weighted term frequency. Let's limit words occuring in at most 90% of documents and in at least 10 documents. \n",
    "- The term-frequency matrix is just a word count, the IDF calculation adjusts for \"boring\" or \"irrelvant\" words that occur in many reviews.\n",
    "\n",
    "- Perform two tokenizing operations. First, tokenize only letters, ignoring special symbols & numbers. \n",
    "- Use the NLTK Snowball stemmer to try and get the root of a word as best as possible. Stop words are removed in the vectorization step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.funfunction()>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def funfunction():\n",
    "    pass\n",
    "\n",
    "funfunction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate TD and IDF\n",
    "# stemmer = SnowballStemmer(\"english\")\n",
    "# tokenizer = RegexpTokenizer(\"[a-z']+\")\n",
    "\n",
    "# def tokenize(text):\n",
    "#     tokens = tokenizer.tokenize(text)\n",
    "#     return [stemmer.stem(t) for t in tokens] \n",
    "\n",
    "\n",
    "\n",
    "def get_tf(data, use_idf, max_df=1.0, min_df=1, ngram_range=(1,1)):\n",
    "    if use_idf:\n",
    "        m = TfidfVectorizer(max_df=max_df, min_df=min_df, stop_words='english', ngram_range=ngram_range, tokenizer=tokenize)\n",
    "    else:\n",
    "        m = CountVectorizer(max_df=max_df, min_df=min_df, stop_words='english', ngram_range=ngram_range, tokenizer=tokenize)\n",
    "    \n",
    "    d = m.fit_transform(data)\n",
    "    return m, d\n",
    "\n",
    "tf_m, tf_d = get_tf(df_pred['predTweet'], use_idf=False, max_df=0.90, min_df=10)\n",
    "tfidf_m, tfidf_d = get_tf(df_pred['predTweet'], use_idf=True, max_df=0.90, min_df=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute topics using Kmeans and LDA\n",
    "\n",
    "- Kmeans approach: Using our TFIDF matrix, cluster documents into N clusters based on their TFIDF similarity. Within each cluster, count the top occuring terms.\n",
    "\n",
    "- LDA approach: Using TF matrix, attempt to extact N topics from the collection of documents.\n",
    "\n",
    "##### Note: Kmeans forces each review to belong to only one cluster while LDA allows a review to have many topics associated with it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's choose 15 topics\n",
    "n_topics = 10\n",
    "\n",
    "# LDA Approach\n",
    "def get_lda(data, topics):\n",
    "    m = LatentDirichletAllocation(n_components=topics, n_jobs=-1, learning_method='online').fit(data)\n",
    "    d = m.transform(data)\n",
    "    return m, d\n",
    "\n",
    "# Kmeans Approach\n",
    "def get_kmeans(data, k, scale=True):\n",
    "    if scale:\n",
    "        s = MinMaxScaler()\n",
    "        data = s.fit_transform(data)\n",
    "    \n",
    "    m = KMeans(n_clusters=k).fit(data)\n",
    "    d = m.predict(data)\n",
    "    return m, d        \n",
    "\n",
    "lda_m, lda_d = get_lda(tf_d, n_topics)\n",
    "kmean_m, kmean_d = get_kmeans(tfidf_d, n_topics, scale=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show cluster top 10 words per topic\n",
    "- First extract the top 10 stemmed words per topic in our LDA model. \n",
    "- Repeate process for kmeans clustered documents. \n",
    "\n",
    "##### Note: Here we just count the top 15 most frequent stemmed words per cluster. Both show similar sets of results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show topics\n",
    "def show_topics(model, feature_names, n_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(\"Topic #%d:\" % topic_idx)\n",
    "        print(\", \".join([feature_names[i]\n",
    "                        for i in topic.argsort()[:-n_words - 1:-1]]))\n",
    "    print()\n",
    "    \n",
    "# Show Clusters    \n",
    "def show_cluster_topics(cluster_labels, tf_matrix, feature_names, n_words):\n",
    "    d = pd.DataFrame(tf_matrix.toarray())\n",
    "    d['c'] = cluster_labels\n",
    "    d = d.groupby('c').sum().T\n",
    "    \n",
    "    for col in d:\n",
    "        top_n = d[col].nlargest(n_words).index.tolist()\n",
    "        print(\"Cluster #%d:\" % col)\n",
    "        print(\", \".join([feature_names[i]\n",
    "                for i in top_n]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LDA topic \n",
    "print(\"Top 10 stemmed words per topic in LDA model\\n\")\n",
    "show_topics(lda_m, tf_m.get_feature_names(), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Kmean cluster of words\n",
    "print(\"Top 10 stemmed words per cluster in Kmeans model\\n\")\n",
    "show_cluster_topics(kmean_d, tfidf_d, tfidf_m.get_feature_names(),20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data for plotting\n",
    "- TF/TFIDF matricies is a challenge to graphically represent documents as charts are limited to 3 dimensions. \n",
    "- Perform a heirarchical clustering, but the number of documents makes this approach very slow. \n",
    "- Let's perform a SVD/LSA to reduce the dimensionality of the matrix to something more manageable (eg. 30 dimensions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_svd(data, components):\n",
    "    svd = TruncatedSVD(n_components=components).fit(data)\n",
    "    o = pd.DataFrame(svd.transform(data), columns=range(0,components))\n",
    "    return svd,o\n",
    "\n",
    "def get_tsne(data, components, perplexity):\n",
    "    tsne = TSNE(n_components=components, perplexity=perplexity, n_iter=1000)\n",
    "    o = pd.DataFrame(tsne.fit_transform(data), columns=range(0,components))\n",
    "    return tsne,o\n",
    "\n",
    "svd_v, svd_m = get_svd(tfidf_d, 30)\n",
    "tnse_v, tsne_m = get_tsne(svd_m, 2, 25)\n",
    "\n",
    "lda_c = lda_d.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Data\n",
    "- Use LDA and Kmeans labels with reduced dimensions to plot our documents. \n",
    "- Create a rainbow color scheme which allows for a variable number of topics/clusters. \n",
    "- The plot tends to overlap quite a bit.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster topc plot\n",
    "def plot_scatter_2d(x, y, c, sample_size, title):\n",
    "    df = pd.DataFrame({'x': x, 'y': y, 'c': c}).sample(sample_size)\n",
    "    l = len(np.unique(c))\n",
    "    \n",
    "    ax = plt.subplot(111)\n",
    "    colors = cm.rainbow(np.linspace(0, 1, l))\n",
    "                                   \n",
    "    for c in range(0,l):\n",
    "        qq = df[df['c']==c]\n",
    "        ax.scatter(qq['x'], qq['y'], label=c)\n",
    "    plt.legend(loc='upper left', numpoints=1, ncol=3, fontsize=8, bbox_to_anchor=(0, 0), title='Topic/Cluster')\n",
    "    ax.set_yticklabels([])\n",
    "    ax.set_xticklabels([])\n",
    "    ax.set_title(title)\n",
    "    plt.show()\n",
    "\n",
    "# Plot\n",
    "plot_scatter_2d(tsne_m[0], tsne_m[1], kmean_d, 1000, 'KMeans Clustering of Tweeter Sentiment using TFIDF (t-SNE Plot)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LDA topics plot\n",
    "plot_scatter_2d(tsne_m[0], tsne_m[1], lda_c, 1000, 'LDA Topics of Tweeter Sentiment using TF (t-SNE Plot)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data for prediction\n",
    "- Scatter plots helps to understand how the data is structured, but it doesn't tell what drives positive or negative reviews. - - Lets use words within reviews to build a predictive scoring model.\n",
    "- When training models, split the data 70%/30% where 30% will be used for prediction to gauge final accuracy of the model.\n",
    "- For each review, the model that scores the highest will tell us which kind of review it likely is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(tfidf_d, df_pred['Sentiment'], test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate model accuracies\n",
    "- Three different approaches to build the review predictions: Logistic Regression, Naive Bayes, and Support Vector Machines. \n",
    "- Final approach that does a combined \"vote\" of all three models. \n",
    "- Since we have limited data, lets use cross-validation to split the data 10 ways and measure accuracy in an unbiased way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate cross validation score\n",
    "cat = [\"Positive\",\"Negative\",\"Neutral\"]\n",
    "def calculate_cv(X, y):\n",
    "    results = {\n",
    "        'lr': [],\n",
    "        'svm': [],\n",
    "        'nb': [],\n",
    "        'combined': []\n",
    "    }\n",
    "    lm = LogisticRegression()\n",
    "    svm = LinearSVC()\n",
    "    nb = MultinomialNB()\n",
    "    vc = VotingClassifier([('lm', lm), ('svm', svm), ('nb', nb)])\n",
    "    \n",
    "    for c in cat:\n",
    "        y_adj = np.array(y==c)\n",
    "        results['lr'].append((cross_val_score(lm, X, y_adj, cv=10, scoring='accuracy').mean(), c))\n",
    "        results['svm'].append((cross_val_score(svm, X, y_adj, cv=10, scoring='accuracy').mean(), c))\n",
    "        results['nb'].append((cross_val_score(nb, X, y_adj, cv=10, scoring='accuracy').mean(), c))\n",
    "        results['combined'].append((cross_val_score(vc, X, y_adj, cv=10, scoring='accuracy').mean(), c))\n",
    "    return results\n",
    "\n",
    "# Call function\n",
    "cv_scores = calculate_cv(X_test, y_test)\n",
    "\n",
    "# print model accuracy predictions\n",
    "\n",
    "print(\"Model accuracy predictions\\n\")\n",
    "for m,s in cv_scores.items():\n",
    "    for ss in s:\n",
    "        print(\"{M} model ({R} rating): {S:.1%}\".format(M=m.upper(), R=ss[1], S=ss[0]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model of choice\n",
    "- SVM have given better performance for. There is definitely room for improvement.  \n",
    "\n",
    "- There are lots of ways to tweak the prior steps to get a better result.\n",
    "\n",
    "    - Tweak any parameters in either the TF step or the modeling step\n",
    "    - Neg/Pos keywords might vary by topic so we might do this for one cluster at a time\n",
    "    - Nouns don't provide much insight and we are better off removing them\n",
    "    - \"good\" and \"not good\" have opposite meanings so maybe we should have included 2-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = [\"Positive\",\"Negative\",\"Neutral\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build linear regression model and fit \n",
    "def get_lr(x, y):\n",
    "    models = []\n",
    "    for c in cat:\n",
    "        y_adj = np.array(y==c)\n",
    "        lm = LogisticRegression()\n",
    "        lm_f = lm.fit(x, y_adj)\n",
    "        models.append(lm_f)\n",
    "    return models\n",
    "\n",
    "lr_m = get_lr(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the results\n",
    "- Charts show the result of Logistic Regression model. \n",
    "- Top 10 words negatively associated (red) with that review model, and the top 10 words positively associated (green) with that review model. \n",
    "- The values indiciate how much more likely or unlikely a review is to be low, neutral, high given the # of times that word occurs in the review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot coefficient \n",
    "\n",
    "def plot_coef(title, model, feature_names, n_words):\n",
    "    v = []\n",
    "    for topic_idx, topic in enumerate(model.coef_):\n",
    "        [v.append([feature_names[i], model.coef_.item(i)]) for i in topic.argsort()[:-n_words - 1:-1]]\n",
    "        [v.append([feature_names[i], model.coef_.item(i)]) for i in topic.argsort()[0:n_words]]\n",
    "    \n",
    "    df = pd.DataFrame(v, columns=['Term','Coefficient']).sort_values(by='Coefficient',ascending=False)\n",
    "    \n",
    "    df['c'] = df['Coefficient']>0\n",
    "    \n",
    "    ax = df.plot(x='Term', y='Coefficient', kind='barh', color=df['c'].map({True: 'g', False: 'r'}), grid=True, legend=False,\n",
    "           title=title)\n",
    "    \n",
    "    ax.set_xlabel(\"Coefficient\")\n",
    "\n",
    "n_terms = 10\n",
    "for c in range(0,len(cat)):\n",
    "    plot_coef('Top {N} words in ({R}) Tweet sentiment model\\nGreen = Associated | Red = Not Associated'.format(N=n_terms*2, \n",
    "               R=cat[c]), lr_m[c], tfidf_m.get_feature_names(), n_terms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test output\n",
    "- Below is a test function which allows to supply review to see how well the model will predict it's rating. \n",
    "- For simplicity, logistic regression model is used and only allow for one review at a time.\n",
    "- The program uses the stored TFIDF matrix to tokenize and transform our new review which is then fed to all three of logistic regression models. \n",
    "- Each model has an independent assessment of how likely it is that our review is a positive hit.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to test sentiment\n",
    "def test_sentiment(text,model):\n",
    "    test_str = [text]\n",
    "    test_new = tfidf_m.transform(test_str)\n",
    "\n",
    "    print('Tweet text: \"{R}\"\\n'.format(R=test_str[0]))\n",
    "    print('Model Predction')\n",
    "    for m in range(0,3):\n",
    "        print('Model ({M}): {P:.1%}'.format(M=cat[m], P=model[m].predict_proba(test_new)[0][1]))       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet text: \"President Trump killed too many people because his COVID19 policies. He should have shut country in early stage.\"\n",
      "\n",
      "Model Predction\n",
      "Model (Positive): 3.8%\n",
      "Model (Negative): 87.0%\n",
      "Model (Neutral): 6.7%\n"
     ]
    }
   ],
   "source": [
    "# Bad sentiment\n",
    "test_sentiment('President Trump killed too many people because his COVID19 policies. He should have shut country in early stage.',lr_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet text: \"President Trump kept his word on trade policies. He is great for the businesses.\"\n",
      "\n",
      "Model Predction\n",
      "Model (Positive): 90.2%\n",
      "Model (Negative): 3.6%\n",
      "Model (Neutral): 7.0%\n"
     ]
    }
   ],
   "source": [
    "# Good sentiment\n",
    "test_sentiment('President Trump kept his word on trade policies. He is great for the businesses.',lr_m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "model_file_name = os.path.join(\"..\",\"Resources\",\"model\",'final_model.pickle')\n",
    "tfidf_model_file_name = os.path.join(\"..\",\"Resources\",\"model\",'tfidf_model.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model \n",
    "pickle.dump(lr_m, open(model_file_name, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save tfd\n",
    "pickle.dump(tfidf_m, open(tfidf_model_file_name, \"wb\"), protocol=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load saved model\n",
    "loaded_model = pickle.load(open(model_file_name, 'rb'))\n",
    "tfidf_model = pickle.load(open(tfidf_model_file_name, \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test string\n",
    "x=\"President Trump kept his word on trade policies. He is great for the businesses\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform test string\n",
    "test_new = tfidf_model.transform([x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model (Positive): 0.9015265715910362\n",
      "Model (Negative): 0.03611988543049171\n",
      "Model (Neutral) 0.06964708736590186\n"
     ]
    }
   ],
   "source": [
    "print(f\"Model (Positive): {loaded_model[0].predict_proba(test_new)[0][1]}\")\n",
    "print(f\"Model (Negative): {loaded_model[1].predict_proba(test_new)[0][1]}\")\n",
    "print(f\"Model (Neutral) {loaded_model[2].predict_proba(test_new)[0][1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check other Models for accurancy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spot Check Algorithms\n",
    "models = []\n",
    "models.append(('LR', LogisticRegression(solver='liblinear', multi_class='ovr')))\n",
    "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('CART', DecisionTreeClassifier()))\n",
    "models.append(('NB', GaussianNB()))\n",
    "models.append(('SVM', SVC(gamma='auto')))\n",
    "models.append(('RF', RandomForestClassifier(n_estimators=100,criterion='entropy',random_state=5)))\n",
    "\n",
    "# evaluate each model in turn\n",
    "results = []\n",
    "names = []\n",
    "for name, model in models:\n",
    "    kfold = StratifiedKFold(n_splits=10, random_state=1, shuffle=True)\n",
    "    cv_results = cross_val_score(model, X_train, y_train, cv=kfold, scoring='accuracy')\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    print('%s: %f (%f)' % (name, cv_results.mean(), cv_results.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
